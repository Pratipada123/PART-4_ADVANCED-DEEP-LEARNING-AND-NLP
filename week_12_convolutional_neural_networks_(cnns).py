# -*- coding: utf-8 -*-
"""Week 12_Convolutional Neural Networks (CNNs).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JRrwcq60_Mvgr9YIXjEfsOyAMnoSaIN1

**What is a Convolutional Neural Network (CNN)?**

- A Convolutional Neural Network (CNN) is a type of deep learning model specially designed for processing visual data like images or videos.
- It automatically learns to extract features such as edges, shapes, textures, and objects from raw pixel values and uses them for classification or recognition tasks.
- Unlike traditional neural networks, CNNs can capture spatial hierarchies ‚Äî meaning they understand how nearby pixels relate to each other ‚Äî making them highly effective for image classification.

**1. Theory: Study CNNs for image classification, layers in CNNs (Convolution,Pooling, Fully Connected).**

**Convolutional Neural Networks (CNNs) for Image Classification**

- CNNs are a special type of deep neural network designed to work with images (2D data).
- They automatically learn patterns like edges, textures, shapes, and objects from raw pixel data ‚Äî making them ideal for tasks like image classification, face recognition, object detection, etc.

**How It Works ‚Äì Step-by-Step**

**Step 1: Input**

- You feed the CNN with an image, e.g., 28√ó28 grayscale or 224√ó224 RGB.
- Each pixel becomes a number (intensity value).

**Step 2: Convolution**

- A filter/kernel (like 3√ó3 or 5√ó5 matrix) slides over the image.
- Performs dot products ‚Üí detects features like edges or corners.
- Multiple filters learn different features automatically.

- Output: A feature map, showing where each pattern occurs.

**Step 3: Activation (ReLU)**

- Applies ReLU (Rectified Linear Unit) ‚Üí replaces negative values with zero.
- Makes the network nonlinear, helping it learn complex patterns.

**Step 4: Pooling (Downsampling)**

- Uses Max Pooling or Average Pooling.
- Example (2√ó2 Max Pooling): keeps the maximum value from every 2√ó2 region.
- Reduces computation, controls overfitting, and maintains key features.

**Step 5: Flatten**

- Converts the 2D feature maps into a 1D vector for the dense layers.

**Step 6: Fully Connected Layers**
    
- Traditional dense neural layers.
- Combine all features to predict the final class (e.g., ‚Äúcat‚Äù, ‚Äúdog‚Äù, ‚Äúcar‚Äù).

**Step 7: Output (Softmax Layer)**

- The Softmax function converts final outputs into probabilities across all classes.

**Advantages**
- Automatically learns features from raw images.
- Reduces manual feature engineering.
- High accuracy on complex image tasks.
- Robust to noise and variations **in images.**

**Applications**
- Fashion AI (outfit classification, try-on)
- Medical imaging (X-ray, MRI classification)
- Autonomous vehicles (object detection)
- Face recognition
- Document digitization (handwriting recognition)
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(64, 64, 3)),
    MaxPooling2D(pool_size=(2,2)),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(pool_size=(2,2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dense(10, activation='softmax')  # 10 classes
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

"""**What is a Convolution Layer?**

- The Convolution Layer is responsible for extracting features (like edges, textures, patterns, and shapes) from the input image.
- It performs a mathematical operation called convolution between the input image and a small filter (kernel).

**How it Works**
**üß© Step-by-step process:**

- A filter (kernel) ‚Äî usually a small matrix (e.g., 3√ó3 or 5√ó5) ‚Äî slides over the input image.

- At each position, the filter and the image patch are multiplied element-wise and summed up to get a single value.

- These values form a feature map (activation map).

- Multiple filters can be used to detect different features.

**Example**
- If you have a 28√ó28 image and apply 32 filters, you‚Äôll get 32 feature maps, each detecting different features.

**Why Convolution Layer is Important**
- Extracts local features (edges, corners, textures)
- Reduces number of parameters compared to fully connected layers
- Preserves spatial relationships between pixels
- Allows deeper layers to learn complex patterns
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, ReLU

model = Sequential([
    Conv2D(filters=32, kernel_size=(3,3), strides=(1,1),
           padding='same', input_shape=(64,64,3)),
    ReLU()
])

model.summary()

"""**What is a Pooling Layer?**

- After the Convolution Layer extracts features (edges, shapes, patterns), the Pooling Layer reduces the spatial size of those feature maps.

**Purpose of Pooling**
- Reduce computation (fewer parameters)
- Prevent overfitting
- Make the model more robust to changes like:
 - small shifts in the image
- rotation or scaling
  - Keep dominant features (edges or textures that matter most).
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D

model = Sequential([
    Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(64,64,3)),
    MaxPooling2D(pool_size=(2,2), strides=2)
])

model.summary()

"""**What is a Fully Connected Layer?**

- A Fully Connected (FC) Layer, also called a Dense Layer, connects every neuron in the previous layer to every neuron in the current layer.
- It acts as a classifier or decision maker that uses all the extracted features from convolution and pooling layers to predict the final output (like cat, dog, car, etc.).

**Why It‚Äôs Needed**

- The convolution and pooling layers extract feature maps (edges, textures, shapes, etc.)
- But to classify or recognize the object, the model needs to combine those features ‚Äî that‚Äôs what the fully connected layer does.

**How It Works**

- Flattening:
  - The final feature maps (e.g., 7√ó7√ó64) are flattened into a 1D vector (e.g., 3136 values).
  - This vector represents all learned features.
- Dense (Fully Connected) Layer:
  - Each feature (input neuron) connects to all output neurons.
  - Every connection has a weight (w) and bias (b).
  - The neuron computes:
  - y=f(Wx+b)
  - where f is an activation function (like ReLU or Softmax).
- Output Layer:
  - Final layer uses Softmax (for multi-class classification) to produce probabilities for each class.
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(64,64,3)),
    MaxPooling2D(pool_size=(2,2)),
    Flatten(),  # Converts 2D ‚Üí 1D
    Dense(128, activation='relu'),  # Fully connected hidden layer
    Dense(10, activation='softmax')  # Output layer for 10 classes
])

model.summary()

"""**Example: Image Classification**

  - Let‚Äôs say the CNN is trained to classify images of animals:
  - Input ‚Üí Image (32√ó32√ó3)
  - Output ‚Üí 3 classes: Cat, Dog, Horse
  - After all convolution and pooling layers:
  - Flattened features ‚Üí [0.2, 0.8, 0.5, ‚Ä¶]
  - Fully connected layer combines these and gives:

**2. Hands-On: Build a CNN for image classification.**

**Objective**

- Build and train a CNN that classifies images ‚Äî for example, using the CIFAR-10 or Fashion MNIST dataset.

**Import Required Libraries**
"""

import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt

"""**Load and Preprocess Dataset**"""

# Load dataset
(X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()

# Normalize pixel values to [0, 1]
X_train = X_train / 255.0
X_test = X_test / 255.0

print("Training data shape:", X_train.shape)
print("Testing data shape:", X_test.shape)

"""**Visualize Some Sample Images**"""

class_names = ['Airplane', 'Car', 'Bird', 'Cat', 'Deer',
               'Dog', 'Frog', 'Horse', 'Ship', 'Truck']

plt.figure(figsize=(8, 8))
for i in range(9):
    plt.subplot(3, 3, i+1)
    plt.imshow(X_train[i])
    plt.title(class_names[y_train[i][0]])
    plt.axis('off')
plt.show()

"""**Build the CNN Model**"""

model = models.Sequential([
    # 1Ô∏è‚É£ Convolution + Pooling Block
    layers.Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)),
    layers.MaxPooling2D((2,2)),

    # 2Ô∏è‚É£ Convolution + Pooling Block
    layers.Conv2D(64, (3,3), activation='relu'),
    layers.MaxPooling2D((2,2)),

    # 3Ô∏è‚É£ Convolution Layer (deeper)
    layers.Conv2D(64, (3,3), activation='relu'),

    # 4Ô∏è‚É£ Flatten + Fully Connected Layers
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')  # Output layer (10 classes)
])

model

"""**Compile the Model**"""

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.summary()

"""**Train the Model**"""

history = model.fit(X_train, y_train, epochs=3,
                    validation_data=(X_test, y_test))
history

"""**Evaluate the Model**"""

test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)
print('\n‚úÖ Test Accuracy:', test_acc)

"""**Plot Accuracy and Loss Curves**"""

plt.figure(figsize=(10,4))
plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.legend()
plt.title('Accuracy')

plt.subplot(1,2,2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.legend()
plt.title('Loss')
plt.show()

"""**Make Predictions**"""

import numpy as np

y_pred = model.predict(X_test)
y_classes = np.argmax(y_pred, axis=1)

# Show sample prediction
plt.imshow(X_test[0])
plt.title(f"Predicted: {class_names[y_classes[0]]}\nActual: {class_names[y_test[0][0]]}")
plt.show()

"""**3. Client Project: Build a CNN model to classify images (e.g., CIFAR-10)**

**Project Objective**

- Build a Convolutional Neural Network (CNN) to classify images from the CIFAR-10 dataset, which contains 60,000 32√ó32 color images in 10 classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck.
- The CNN will automatically extract features and learn patterns to classify new images accurately.

**Tech Stack**

- Programming Language: Python 3.x
**Libraries:**
- TensorFlow / Keras (for deep learning)
- NumPy (numerical operations)
- Matplotlib (visualization)

**Steps to Build the CNN Model**

**Import Required Libraries**
"""

import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt
import numpy as np

"""**Load and Preprocess CIFAR-10 Dataset**"""

# Load CIFAR-10 dataset
(X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()

# Normalize pixel values to range [0,1]
X_train, X_test = X_train / 255.0, X_test / 255.0

# Optional: verify shapes
print("Training data shape:", X_train.shape)
print("Testing data shape:", X_test.shape)

"""**Visualize Sample Images**"""

class_names = ['Airplane','Car','Bird','Cat','Deer','Dog','Frog','Horse','Ship','Truck']

plt.figure(figsize=(8,8))
for i in range(9):
    plt.subplot(3,3,i+1)
    plt.imshow(X_train[i])
    plt.title(class_names[y_train[i][0]])
    plt.axis('off')
plt.show()

"""**Build the CNN Model**"""

model = models.Sequential([
    # Block 1
    layers.Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)),
    layers.MaxPooling2D((2,2)),

    # Block 2
    layers.Conv2D(64, (3,3), activation='relu'),
    layers.MaxPooling2D((2,2)),

    # Block 3
    layers.Conv2D(64, (3,3), activation='relu'),

    # Flatten & Fully Connected
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')
])

"""**Explanation**

- Conv + ReLU ‚Üí feature extraction
- MaxPooling ‚Üí reduce size, retain strongest features
- Flatten ‚Üí prepare for fully connected layer
- Dense ‚Üí classification

**Compile the Model**
"""

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
model.summary()

"""**Train the Model**"""

history = model.fit(X_train, y_train, epochs=3,
                    validation_data=(X_test, y_test))

"""**Evaluate the Model**"""

test_loss, test_acc = model.evaluate(X_test, y_test)
print("‚úÖ Test Accuracy:", test_acc)

"""**Plot Training Curves**"""

plt.figure(figsize=(12,5))

# Accuracy
plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Accuracy')
plt.legend()

# Loss
plt.subplot(1,2,2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Loss')
plt.legend()
plt.show()

"""**Make Predictions**"""

y_pred = model.predict(X_test)
y_classes = np.argmax(y_pred, axis=1)

# Example: display first test image
plt.imshow(X_test[0])
plt.title(f"Predicted: {class_names[y_classes[0]]}, Actual: {class_names[y_test[0][0]]}")
plt.show()

"""**Optional Enhancements**

- Data Augmentation: ImageDataGenerator for rotation, flips, zoom
- Dropout layers: Reduce overfitting
- Batch Normalization: Stabilize training
- More Convolutional Layers: Deeper network for higher accuracy

**Deployment Ideas**

- Streamlit App: Upload image ‚Üí predict class ‚Üí show result
- Flask API: Expose a REST API for image classification
- Export Model:
"""

model.save('cnn_cifar10_model.h5')